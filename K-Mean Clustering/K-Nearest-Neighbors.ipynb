{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 : always set up our dependencies first\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes : 3 \n",
      "Number of data point : 150\n",
      "\n",
      "First 5 samples from class 0 :\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "\n",
      "First 5 samples from class 1 :\n",
      " [[7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]]\n",
      "\n",
      "First 5 samples from class 2 :\n",
      " [[6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]]\n",
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "#Step 2: We now seperate our data\n",
    "iris = datasets.load_iris()\n",
    "#total data we have including 4 differnent character\n",
    "#that we will use to analyze the model\n",
    "iris_x = iris.data \n",
    "#total label of the data\n",
    "iris_y = iris.target\n",
    "\n",
    "print('Number of classes : %d ' %len(np.unique(iris_y)))\n",
    "print(\"Number of data point : %d\" %len(iris_y))\n",
    "\n",
    "X0 = iris_x[iris_y == 0,:]\n",
    "print(\"\\nFirst 5 samples from class 0 :\\n\" ,X0[:5,])\n",
    "\n",
    "X1 = iris_x[iris_y == 1,:]\n",
    "print(\"\\nFirst 5 samples from class 1 :\\n\" ,X1[:5,])\n",
    "\n",
    "X2 = iris_x[iris_y == 2,:]\n",
    "print(\"\\nFirst 5 samples from class 2 :\\n\" ,X2[:5,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning size  100\n",
      "Testing size  50\n"
     ]
    }
   ],
   "source": [
    "#Step 3: We are now dividing our datasets into training and testing sets\n",
    "#Now we know that we have 150 different datapoints in our datasets\n",
    "#assume that we want to have 50 datapoints for testing and 100 datapoints for testings\n",
    "#So we can devide the divide the datasets we have by using \n",
    "# sklearn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris_x,iris_y,test_size = 50)\n",
    "print(\"Trainning size \",len(y_train))\n",
    "print(\"Testing size \",len(y_test))\n",
    "#After this we have 50 testing points and 100 training points \n",
    "#with label y corresponding to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the result of 20 test data points: \n",
      "Our prediction from the y_pred    : [0 0 1 2 2 1 1 1 0 0 2 0 0 2 2 0 1 1 2 0]\n",
      "Our correct result from the y_test: [0 0 1 2 2 1 2 1 0 0 2 0 0 2 2 0 1 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "#Step4.1: We now assuming that K = 1. \n",
    "# This means we use one point of training data and take the label to predict for the\n",
    "#testing point\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 1, p = 2)\n",
    "#traning the model with the coressponding \n",
    "#data and its labels\n",
    "clf.fit(X_train,y_train)\n",
    "#Now we compute our prediction with the X_test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#then we now try to compare the result from our prediction\n",
    "#with the actual results y_test\n",
    "\n",
    "print(\"Print the result of 20 test data points: \")\n",
    "print(\"Our prediction from the y_pred    :\" , y_pred[20:40])\n",
    "print(\"Our correct result from the y_test:\" , y_test[20:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is 98.000000\n"
     ]
    }
   ],
   "source": [
    "#Step 5 : Evaluation method:\n",
    "#We can you another library from the sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"The accuracy of our model is %f\"  %(100*accuracy_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is 96.000000\n"
     ]
    }
   ],
   "source": [
    "#Step 4.2: We try to optimize our model by\n",
    "#increasing the number of neighbors that\n",
    "#we will increase the n_neighbor =10\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2)\n",
    "#traning the model with the coressponding \n",
    "#data and its labels\n",
    "clf.fit(X_train,y_train)\n",
    "#Now we compute our prediction with the X_test set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"The accuracy of our model is %f\"  %(100*accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is 98.000000\n"
     ]
    }
   ],
   "source": [
    "#Step 6: Then we try to optimize the productivity of the\n",
    "#model by letting the point that close to neighbor\n",
    "#to have bigger weights (this is fair)\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = 'distance')\n",
    "#traning the model with the coressponding \n",
    "#data and its labels\n",
    "clf.fit(X_train,y_train)\n",
    "#Now we compute our prediction with the X_test set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"The accuracy of our model is %f\"  %(100*accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is 98.000000\n"
     ]
    }
   ],
   "source": [
    "#Step 7: now we can also calculate our own\n",
    "#weights by create a small function and \n",
    "#add it to the clf \n",
    "\n",
    "def myweight(distances):\n",
    "    sigma2 = .5\n",
    "    return np.exp(-distances**2/sigma2)\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = myweight)\n",
    "#traning the model with the coressponding \n",
    "#data and its labels\n",
    "clf.fit(X_train,y_train)\n",
    "#Now we compute our prediction with the X_test set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"The accuracy of our model is %f\"  %(100*accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
