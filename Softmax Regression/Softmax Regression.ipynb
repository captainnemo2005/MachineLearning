{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to build soft max function\n",
    "#Step 1: Import our dependency\n",
    "import numpy as np\n",
    "#Step 2: Our softmax\n",
    "def softmax(Z):\n",
    "    \"\"\"Compute softmax values for each sets of scores in V\n",
    "    each column of V is a set of scores\n",
    "    Z: a numpy array of shape(N,C)\n",
    "    return a numpy array of shape (N,C)\n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z) \n",
    "    A = e_Z/e_Z.sum(axis = 1, keepdims = True)\n",
    "    return A\n",
    "#This function will face hardship when we calculate\n",
    "#big set of number since the exp will take more time\n",
    "#to calculate\n",
    "# So will can develop new and stable function\n",
    "def softmax_stable(Z):\n",
    "    \"\"\" We now can minus the whole array with the \n",
    "    largest number inside of Z.\n",
    "    Then we repeat the whole process like what we do in\n",
    "    the softmax above\n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z - np.max(Z,axis = 1, keepdims = True)) \n",
    "    A = e_Z/e_Z.sum(axis = 1 , keepdims = True)\n",
    "    return A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: making our loss function\n",
    "def softmax_loss(X,y,W):\n",
    "    \"\"\"W : 2d array of shape (d,C)\n",
    "    each column corresponding to 1 output node\n",
    "    X: 2d array of shapem(N,d) - each row corresponding to 1 data point\n",
    "    y: 1d array -- label of each point in X\n",
    "    \"\"\"\n",
    "    A = softmax_stable(X.dot(W))\n",
    "    id0 = range(X.shape[0]) #This is the index number starting from number of row inside X\n",
    "    return -np.mean(np.log(A[id0,y])) #Just the formular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Optimize the loss function by using the\n",
    "# mini batch gradient descent\n",
    "def softmax_grad(X,y,W):\n",
    "    \"\"\"W : 2d array of shape (d,C)\n",
    "    each column corresponding to 1 output node\n",
    "    X: 2d array of shapem(N,d) - each row corresponding to 1 data point\n",
    "    y: 1d array -- label of each point in X\n",
    "    \"\"\"\n",
    "    A = softmax_stable(X.dot(W))\n",
    "    id0 = range(X.shape[0])\n",
    "    A[id0, y ] -= 1 # A-Y\n",
    "    return X.T.dot(A)/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: fit our model\n",
    "def softmax_fit(X,y,W, lr = 0.01, nepochs = 1000, tol = 1e-5 , batch_size = 10):\n",
    "    W_old = W.copy()\n",
    "    ep = 0 #For iteration\n",
    "    loss_hist = [softmax_loss(X,y,W)] #store history of loss\n",
    "    N = X.shape[0]\n",
    "    nbatches = int(np.ceil(float(N)/batch_size))#take the total size\n",
    "    while ep < nepochs:\n",
    "        ep += 1\n",
    "        mix_ids = np.random.permutation(N) # mix the data\n",
    "        for i in range(nbatches):\n",
    "            #Get the ith batch \n",
    "            #This line just got a bunch of 10 data point's index = batch size during an iteration\n",
    "            batch_ids = mix_ids[batch_size*i:min(batch_size*(i+1) , N)]\n",
    "            #actually taking the data\n",
    "            X_batch , y_batch = X[batch_ids], y[batch_ids]\n",
    "            #update the GD\n",
    "            W -= lr*softmax_grad(X_batch,y_batch,W)\n",
    "        loss_hist.append(softmax_loss(X,y,W))\n",
    "        if np.linalg.norm(W - W_old)/W.size < tol:\n",
    "            break\n",
    "        W_old = W.copy()\n",
    "    return W, loss_hist\n",
    "#Step 5: Making our prediction\n",
    "def pred(X,W):\n",
    "    return np.argmax(X.dot(W), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04942752750806835\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12997c78198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now we are going to actually creating data and feed it \n",
    "#to our model\n",
    "C, N = 5, 500\n",
    "means = [[2,2], [8,3] ,[3,6],[14,2],[12,8]]\n",
    "cov = [[1,0],[0,1]]\n",
    "#generating the data\n",
    "X0 = np.random.multivariate_normal(means[0],cov,N)\n",
    "X1 = np.random.multivariate_normal(means[1],cov,N)\n",
    "X2 = np.random.multivariate_normal(means[2],cov,N)\n",
    "X3 = np.random.multivariate_normal(means[3],cov,N)\n",
    "X4 = np.random.multivariate_normal(means[4],cov,N)\n",
    "#Combine them horizontally so we have each row is a data point\n",
    "X = np.concatenate((X0,X1,X2,X3,X4), axis = 0)\n",
    "Xbar = np.concatenate((X,np.ones((X.shape[0], 1))), axis = 1)\n",
    "#Setting the label\n",
    "y = np.asarray(N*[0] + N*[1]+ N*[2]+ N*[3] + N*[4])\n",
    "W_init = np.random.randn(Xbar.shape[1] , C)\n",
    "W, loss = softmax_fit(Xbar,y,W_init,lr = 0.01, nepochs = 1000, tol = 1e-5 , batch_size = 10 )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(loss[-1])\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 448000)\n",
      "(448000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "448000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "xm = np.arange(-2, 18, 0.025)\n",
    "xlen = len(xm)\n",
    "ym = np.arange(-3, 11, 0.025)\n",
    "ylen = len(ym)\n",
    "xx, yy = np.meshgrid(xm, ym)\n",
    "\n",
    "\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "# xx.ravel(), yy.ravel()\n",
    "\n",
    "print(np.ones((1, xx.size)).shape)\n",
    "xx1 = xx.ravel().reshape(-1, 1)\n",
    "yy1 = yy.ravel().reshape(-1, 1)\n",
    "\n",
    "# print(xx.shape, yy.shape)\n",
    "XX = np.concatenate(( xx1, yy1, np.ones(( xx.size, 1))), axis = 1)\n",
    "\n",
    "\n",
    "print(XX.shape)\n",
    "\n",
    "Z = pred(XX,W)\n",
    "\n",
    "len(yy1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
